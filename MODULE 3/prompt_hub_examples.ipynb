{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangSmith Prompt Hub Examples\n",
    "This notebook demonstrates working with LangSmith Prompt Hub including pulling prompts, creating custom prompts, and pushing them to the hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Pull prompt from LangSmith Hub\n",
    "from langsmith import Client\n",
    "import os\n",
    "\n",
    "client = Client(api_key=os.getenv(\"LANGSMITH_API_KEY\"))\n",
    "prompt = client.pull_prompt(\"scientist-philosopher\", include_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: View the prompt structure\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Invoke the prompt with a question about AI\n",
    "result_ai = prompt.invoke({\n",
    "    \"question\": \"What is artificial intelligence and how does it relate to human consciousness?\"\n",
    "})\n",
    "result_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Invoke with a question about the universe\n",
    "result_universe = prompt.invoke({\n",
    "    \"question\": \"What is the origin and fate of the universe?\"\n",
    "})\n",
    "result_universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Invoke with a question about quantum mechanics\n",
    "result_quantum = prompt.invoke({\n",
    "    \"question\": \"How does quantum entanglement challenge our understanding of reality?\"\n",
    "})\n",
    "result_quantum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Create and push a custom RAG prompt for medical queries\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "medical_prompt = \"\"\"You are a medical knowledge assistant for healthcare professionals.\n",
    "Use the following retrieved medical literature to answer the question accurately.\n",
    "\n",
    "Always cite your sources and acknowledge limitations of the information provided.\n",
    "\n",
    "Context: {context}\n",
    "Medical History: {patient_history}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "medical_prompt_template = ChatPromptTemplate.from_template(medical_prompt)\n",
    "client.push_prompt(\"medical-rag-assistant\", object=medical_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Create and push a code review prompt with model\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "code_review_prompt = \"\"\"You are an expert code reviewer specializing in {language}.\n",
    "\n",
    "Review the following code for:\n",
    "1. Bug detection\n",
    "2. Performance optimization\n",
    "3. Security vulnerabilities\n",
    "4. Best practices\n",
    "\n",
    "Code to review:\n",
    "{code}\n",
    "\n",
    "Previous feedback: {previous_feedback}\n",
    "\n",
    "Provide a detailed review:\"\"\"\n",
    "\n",
    "code_review_template = ChatPromptTemplate.from_template(code_review_prompt)\n",
    "code_chain = code_review_template | model\n",
    "client.push_prompt(\"code-review-chain\", object=code_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Pull and test the medical prompt\n",
    "medical_prompt_pulled = client.pull_prompt(\"medical-rag-assistant\")\n",
    "test_medical = medical_prompt_pulled.invoke({\n",
    "    \"context\": \"Recent studies show correlation between vitamin D deficiency and immune system weakness.\",\n",
    "    \"patient_history\": \"45-year-old with recurring infections\",\n",
    "    \"question\": \"Could vitamin D supplementation help boost immunity?\"\n",
    "})\n",
    "test_medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Create a data analysis prompt\n",
    "data_analysis_prompt = \"\"\"You are a data scientist analyzing {dataset_type} data.\n",
    "\n",
    "Dataset Description: {dataset_description}\n",
    "Analysis Goals: {goals}\n",
    "Available Columns: {columns}\n",
    "\n",
    "Provide:\n",
    "1. Key insights from the data\n",
    "2. Statistical observations\n",
    "3. Recommendations for further analysis\n",
    "4. Potential data quality issues\n",
    "\n",
    "Analysis:\"\"\"\n",
    "\n",
    "data_template = ChatPromptTemplate.from_template(data_analysis_prompt)\n",
    "client.push_prompt(\"data-analysis-assistant\", object=data_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Test with multiple philosophical questions\n",
    "result_consciousness = prompt.invoke({\n",
    "    \"question\": \"What is consciousness and can machines truly achieve it?\"\n",
    "})\n",
    "print(\"Consciousness query:\", result_consciousness)\n",
    "\n",
    "result_meaning = prompt.invoke({\n",
    "    \"question\": \"What is the meaning of life from both scientific and philosophical perspectives?\"\n",
    "})\n",
    "print(\"\\nMeaning of life query:\", result_meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Create a creative writing prompt\n",
    "creative_prompt = \"\"\"You are a creative writing mentor helping with {genre} writing.\n",
    "\n",
    "Story Elements:\n",
    "- Setting: {setting}\n",
    "- Main Character: {character}\n",
    "- Conflict: {conflict}\n",
    "- Theme: {theme}\n",
    "\n",
    "Provide creative suggestions for:\n",
    "1. Plot development\n",
    "2. Character arc\n",
    "3. Dialogue examples\n",
    "4. Atmospheric descriptions\n",
    "\n",
    "Suggestions:\"\"\"\n",
    "\n",
    "creative_template = ChatPromptTemplate.from_template(creative_prompt)\n",
    "creative_chain = creative_template | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.8)\n",
    "client.push_prompt(\"creative-writing-mentor\", object=creative_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Summary\n",
    "print(\"All prompts created and tested successfully!\")\n",
    "print(\"\\nPrompts pushed to LangSmith Hub:\")\n",
    "print(\"1. medical-rag-assistant\")\n",
    "print(\"2. code-review-chain\")\n",
    "print(\"3. data-analysis-assistant\")\n",
    "print(\"4. creative-writing-mentor\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
